{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro"
      },
      "source": [
        "# KUx Colab End-to-End Notebook\n",
        "This notebook provisions the KUx multimodal assistant on **Google Colab Pro+ (A100 80GB)**.\n",
        "Follow the sections sequentially to install dependencies, prepare Retrieval-Augmented Generation (RAG) data, optionally fine-tune Qwen3-Omni, and launch the chatbot demo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "runtime"
      },
      "source": [
        "## 1. Check GPU runtime\n",
        "Confirm the Colab session is running on an A100 80GB GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvidia_smi",
        "colab": {
          "background_save": true
        }
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clone"
      },
      "source": [
        "## 2. Clone KUx and install dependencies\n",
        "Set `REPO_URL` to your fork if you maintain a custom version. Editable installation exposes the `kux` package for the helper scripts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "REPO_URL = 'https://github.com/themistymoon/KUx.git'\n",
        "PROJECT_ROOT = '/content/KUx'\n",
        "\n",
        "!git clone $REPO_URL\n",
        "%cd $PROJECT_ROOT\n",
        "!pip install -U pip\n",
        "!pip install -r requirements.txt\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "transformers"
      },
      "source": [
        "### (Optional) Update Transformers nightly\n",
        "Upgrade to the bleeding-edge Transformers build when Colab ships an older release than required by Qwen3-Omni's multimodal features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "transformers_upgrade"
      },
      "outputs": [],
      "source": [
        "# !pip install -U \"transformers@git+https://github.com/huggingface/transformers\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drive"
      },
      "source": [
        "## 3. (Optional) Mount Google Drive\n",
        "Persist FAISS indexes and LoRA adapters between sessions by mounting Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drive_mount"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf_login"
      },
      "source": [
        "## 4. Authenticate with Hugging Face (if needed)\n",
        "Login to access gated models or higher rate limits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf_login_code"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paths"
      },
      "source": [
        "## 5. Configure storage locations\n",
        "Set directories for RAG storage and optional LoRA adapters. Update these paths if you mounted Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config_paths"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "VECTOR_DB_DIR = Path('storage/vectorstore')\n",
        "ADAPTER_DIR = Path('outputs/finetuned-qwen')\n",
        "DATA_DIR = Path('data')\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "VECTOR_DB_DIR.mkdir(parents=True, exist_ok=True)\n",
        "ADAPTER_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print('Vector DB directory:', VECTOR_DB_DIR.resolve())\n",
        "print('Adapter output directory:', ADAPTER_DIR.resolve())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload_dataset"
      },
      "source": [
        "## 6. Upload supervision dataset (optional)\n",
        "Upload `train.jsonl` or other fine-tuning assets into the `data/` directory via Colab's file browser. Each line should contain either chat-style `{\"messages\": [...]}` entries or `{\"instruction\": ..., \"response\": ...}` pairs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crawl"
      },
      "source": [
        "## 7. Crawl Kasetsart sources (optional)\n",
        "Harvest approved KU pages to enrich the RAG corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crawl_code"
      },
      "outputs": [],
      "source": [
        "CRAWL_OUTPUT = DATA_DIR / 'crawled'\n",
        "CRAWL_OUTPUT.mkdir(exist_ok=True)\n",
        "\n",
        "# Example crawl of the KU Computer Science site (adjust domains, depth, and page limits as needed).\n",
        "# !python scripts/crawl_sites.py https://cs.sci.ku.ac.th --output $CRAWL_OUTPUT --max-depth 1 --max-pages 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ingest"
      },
      "source": [
        "## 8. Build or update the FAISS vector store\n",
        "Point the ingestion script at directories or files containing PDFs (\u226420 pages recommended), CSVs, Markdown, or plain text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ingest_code"
      },
      "outputs": [],
      "source": [
        "import shlex, subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "PDF_DIRS = []  # e.g., [DATA_DIR / 'handbooks']\n",
        "CSV_DIRS = []  # e.g., [DATA_DIR / 'datasets']\n",
        "CRAWL_DIRS = [CRAWL_OUTPUT]  # include crawled text\n",
        "\n",
        "def collect_existing(paths):\n",
        "    collected = []\n",
        "    for path in paths:\n",
        "        p = Path(path)\n",
        "        if p.exists():\n",
        "            collected.append(p)\n",
        "    return collected\n",
        "\n",
        "normalized_paths = (\n",
        "    collect_existing(PDF_DIRS) +\n",
        "    collect_existing(CSV_DIRS) +\n",
        "    collect_existing(CRAWL_DIRS)\n",
        ")\n",
        "if normalized_paths:\n",
        "    cmd = ['python', 'scripts/build_vector_store.py', *map(str, normalized_paths), '--vector-db', str(VECTOR_DB_DIR)]\n",
        "    print('Running:', ' '.join(shlex.quote(part) for part in cmd))\n",
        "    subprocess.run(cmd, check=True)\n",
        "else:\n",
        "    print('\u26a0\ufe0f  No existing document directories found. Upload PDFs/CSVs or enable crawling before ingesting.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train"
      },
      "source": [
        "## 9. Fine-tune Qwen (optional)\n",
        "Train LoRA adapters on your supervision dataset. Adjust hyperparameters with CLI flags or JSON configs if desired."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_code"
      },
      "outputs": [],
      "source": [
        "import shlex, subprocess\n",
        "\n",
        "DATASET_PATH = DATA_DIR / 'train.jsonl'\n",
        "if DATASET_PATH.exists():\n",
        "    cmd = [\n",
        "        'python', 'scripts/train_qwen.py',\n",
        "        '--dataset', str(DATASET_PATH),\n",
        "        '--output-dir', str(ADAPTER_DIR)\n",
        "    ]\n",
        "    print('Running:', ' '.join(shlex.quote(part) for part in cmd))\n",
        "    subprocess.run(cmd, check=True)\n",
        "else:\n",
        "    print('\u2139\ufe0f  Skipping fine-tuning because data/train.jsonl is not present.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "launch"
      },
      "source": [
        "## 10. Launch the KUx chatbot\n",
        "Start the Gradio app with configurable model, adapter, and system prompt settings. The UI will display text, audio, image, and video inputs when a multimodal model is selected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "launch_code"
      },
      "outputs": [],
      "source": [
        "import shlex, subprocess\n",
        "\n",
        "MODEL_KEY = 'qwen3-omni-30b'  # or 'gpt-oss-120b' for text-only\n",
        "SYSTEM_PROMPT = (\n",
        "    'You are KUx, a Kasetsart University assistant. Provide verified guidance for the Computer Science programme.'\n",
        ")\n",
        "\n",
        "cmd = [\n",
        "    'python', 'scripts/run_chatbot.py',\n",
        "    '--model', MODEL_KEY,\n",
        "    '--system-prompt', SYSTEM_PROMPT,\n",
        "    '--vector-db', str(VECTOR_DB_DIR),\n",
        "    '--share'\n",
        "]\n",
        "if ADAPTER_DIR.exists() and any(ADAPTER_DIR.iterdir()):\n",
        "    cmd.extend(['--adapter', str(ADAPTER_DIR)])\n",
        "\n",
        "print('Running:', ' '.join(shlex.quote(part) for part in cmd))\n",
        "subprocess.run(cmd, check=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shutdown"
      },
      "source": [
        "## 11. Shutdown (optional)\n",
        "To stop the Gradio server, interrupt the cell above or run the following."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shutdown_code"
      },
      "outputs": [],
      "source": [
        "# !pkill -f gradio"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "KUx_Colab_End_to_End.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}